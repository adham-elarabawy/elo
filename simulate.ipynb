{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choices\n",
    "from itertools import combinations\n",
    "import math\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Initial parameters\n",
    "n_players = 5\n",
    "initial_elo = 1500\n",
    "n_rounds = 2000\n",
    "K = 1\n",
    "\n",
    "# Define window size for running average\n",
    "window_size = 50\n",
    "\n",
    "# Set up bias factors\n",
    "bias_factors = [0.6, 0.8, 1.0, 1.2, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate expected score\n",
    "def expected_score(rating1, rating2):\n",
    "    return 1 / (1 + 10**((rating2 - rating1) / 400))\n",
    "\n",
    "# Function to update ratings after a game\n",
    "def update_elo(rating1, rating2, score1, K):\n",
    "    expected1 = expected_score(rating1, rating2)\n",
    "    return rating1 + K * (score1 - expected1)\n",
    "\n",
    "def compute_expected_elo(rating, prob_of_winning):\n",
    "    return rating + 400 * math.log10(prob_of_winning)\n",
    "    # return rating + 400 * np.log10(1 / prob_of_winning - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_elo = [compute_expected_elo(initial_elo, bias_factor) for bias_factor in bias_factors]\n",
    "\n",
    "# Reset initial ratings\n",
    "ratings = [initial_elo for _ in range(n_players)]\n",
    "\n",
    "# Simulate rounds with bias\n",
    "history = [list(ratings)]\n",
    "# for i in range(n_players):\n",
    "    #     for j in range(i + 1, n_players):\n",
    "for _ in range(n_rounds):\n",
    "    for i, j in combinations(range(n_players), 2):\n",
    "        # Determine game outcome based on current ratings and bias factors\n",
    "        players = [i, j]\n",
    "        # weights = [ratings[i] * bias_factors[i], ratings[j] * bias_factors[j]]\n",
    "        weights = [bias_factors[i], bias_factors[j]]\n",
    "        winner = choices(players, weights=weights, k=1)[0]\n",
    "        \n",
    "        # Update ratings\n",
    "        if winner == i:\n",
    "            ratings[i] = update_elo(ratings[i], ratings[j], 1, K)\n",
    "            ratings[j] = update_elo(ratings[j], ratings[i], 0, K)\n",
    "        else:\n",
    "            ratings[i] = update_elo(ratings[i], ratings[j], 0, K)\n",
    "            ratings[j] = update_elo(ratings[j], ratings[i], 1, K)\n",
    "    \n",
    "    # Record ratings after this round\n",
    "    history.append(list(ratings))\n",
    "\n",
    "# Convert history to DataFrame for easy plotting\n",
    "history_df = pd.DataFrame(history, columns=[f'Player {i+1}' for i in range(n_players)])\n",
    "\n",
    "# Create a colormap\n",
    "colors = plt.get_cmap('Set3') # tab10\n",
    "\n",
    "# Apply running average filter\n",
    "history_df_smooth = history_df.rolling(window_size).mean()\n",
    "\n",
    "# Plotting the ELO ratings over time with bias factors and more rounds\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, player in enumerate(history_df_smooth.columns):\n",
    "    # Plot smoothed data\n",
    "    plt.plot(history_df_smooth[player], label=player + ' (Smoothed)', color=colors(i))\n",
    "    # Plot original data with lower opacity\n",
    "    plt.plot(history_df[player], alpha=0.3, color=colors(i))\n",
    "    # Plot expected Elo rating\n",
    "    plt.axhline(y=expected_elo[i], linestyle='--', color=colors(i)) # , label=player + ' (Expected)'\n",
    "\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Elo Rating')\n",
    "plt.title(f'Simulated Elo Ratings Over Time ({n_rounds} Rounds, Smoothed)')\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
